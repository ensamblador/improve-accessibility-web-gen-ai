{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de Imagenes para texto alternativo usando contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from IPython.display import display, HTML\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Crea el cliente Bedrock usando SDK de AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "bedrock = boto3.client(\"bedrock-runtime\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analiza la imagen y crea el texto alternativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./samples/sample_diagram.jpg\"\n",
    "\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    content_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "\n",
    "\n",
    "previous_text = \"...En la imagen se muestra el uso de LLM para entender las imagenes dentro del texto y proveer buqueda más relevante en Bases de Datos Vectoriales.\"\n",
    "following_text = \"Ahora veamos el caso donde un usuario quiera encontrar documentos donde se muestra la invocación a bedrock...\"\n",
    "\n",
    "\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\":\"text\",\"text\":previous_text},\n",
    "        {\n",
    "            \"type\": \"image\", \n",
    "            \"source\": {\n",
    "                \"type\": \"base64\", \n",
    "                \"media_type\": \"image/jpeg\", \n",
    "                \"data\": content_image\n",
    "            }\n",
    "        },\n",
    "        {\"type\":\"text\",\"text\":following_text}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "system_prompt = \"Tu eres un revisor de articulos web que van a ser publicados, tu misión es ver las imágenes y leer el texto previo y posterior para proporcionar un texto alternativo (que se incluirá como atributo 'alt' para la etiqueta img) que describa su contenido. Considera el texto que viene antes y después de la imagen. Responde en 150 caracteres o menos sin preámbulo\"\n",
    "\n",
    "body = {\n",
    "    \"system\": system_prompt,\n",
    "    \"messages\":[message],\"anthropic_version\":\"bedrock-2023-05-31\",\"max_tokens\":100, \"temperature\":0\n",
    "}\n",
    "\n",
    "response = bedrock.invoke_model(body=json.dumps(body), modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "alt_text = response_body.get(\"content\")[0].get(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Texto Alternativo:</strong><br/>Diagrama que muestra el flujo de invocación de un modelo de lenguaje grande (LLM) en AWS Cloud para generar una descripción de una imagen, utilizada para búsquedas más relevantes en bases de datos vectoriales.<br/><img alt='Diagrama que muestra el flujo de invocación de un modelo de lenguaje grande (LLM) en AWS Cloud para generar una descripción de una imagen, utilizada para búsquedas más relevantes en bases de datos vectoriales.' src='./samples/sample_diagram.jpg'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Imagen con alt y src\n",
    "display(HTML(f\"<strong>Texto Alternativo:</strong><br/>{alt_text}<br/><img alt='{alt_text}' src='{image_path}'>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
